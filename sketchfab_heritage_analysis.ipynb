{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# Sketchfab Cultural Heritage Models Analysis\n",
    "\n",
    "This notebook demonstrates how to use the Sketchfab Data API to retrieve and analyze cultural heritage 3D models for discourse analysis.\n",
    "\n",
    "**Research Purpose**: Examining how modelers employ historical discourses in their cultural heritage models on Sketchfab.\n",
    "\n",
    "**API Documentation**: https://docs.sketchfab.com/data-api/v3/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## 1. Setup\n",
    "\n",
    "First, let's install the required dependencies and import the scraper module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install requests pandas matplotlib seaborn wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload_module"
   },
   "outputs": [],
   "source": [
    "# Upload the sketchfab_scraper.py file to Colab\n",
    "# Option 1: Upload manually using the file browser on the left\n",
    "# Option 2: Clone from GitHub (uncomment below)\n",
    "# !git clone https://github.com/your-username/km-sf.git\n",
    "# import sys\n",
    "# sys.path.append('/content/km-sf')\n",
    "\n",
    "# For this example, we'll assume the file is in the current directory\n",
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set pandas display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_scraper"
   },
   "outputs": [],
   "source": [
    "# Import the scraper module\n",
    "from sketchfab_scraper import SketchfabScraper, quick_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "api_token_section"
   },
   "source": [
    "## 2. API Token (Optional)\n",
    "\n",
    "While many searches work without authentication, having an API token may provide access to more data and higher rate limits.\n",
    "\n",
    "**To get your API token:**\n",
    "1. Log in to Sketchfab\n",
    "2. Go to https://sketchfab.com/settings/password\n",
    "3. Find your API token in the settings\n",
    "\n",
    "**Note**: Keep your API token private!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "api_token"
   },
   "outputs": [],
   "source": [
    "# Set your API token here (optional)\n",
    "API_TOKEN = None  # Replace with your token: \"your_api_token_here\"\n",
    "\n",
    "# Initialize the scraper\n",
    "# rate_limit_delay: seconds between requests (increase if you get 429 errors)\n",
    "scraper = SketchfabScraper(api_token=API_TOKEN, rate_limit_delay=1.5)\n",
    "\n",
    "print(\"‚úì Scraper initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "basic_search"
   },
   "source": [
    "## 3. Basic Search Examples\n",
    "\n",
    "Let's start with some basic searches to retrieve cultural heritage models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "search_example_1"
   },
   "outputs": [],
   "source": [
    "# Search for cultural heritage models with a specific query\n",
    "# This uses the convenience method that automatically filters by cultural heritage category\n",
    "df_roman = scraper.search_cultural_heritage(\n",
    "    query=\"roman\",\n",
    "    max_results=50  # Limit to 50 results for this example\n",
    ")\n",
    "\n",
    "print(f\"Found {len(df_roman)} Roman cultural heritage models\")\n",
    "print(\"\\nFirst 5 results:\")\n",
    "df_roman[['name', 'user_username', 'viewCount', 'likeCount']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "search_example_2"
   },
   "outputs": [],
   "source": [
    "# Search for ancient Egyptian models\n",
    "df_egyptian = scraper.search_cultural_heritage(\n",
    "    query=\"ancient egypt\",\n",
    "    max_results=50\n",
    ")\n",
    "\n",
    "print(f\"Found {len(df_egyptian)} Ancient Egyptian models\")\n",
    "df_egyptian[['name', 'user_displayName', 'tags']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "search_example_3"
   },
   "outputs": [],
   "source": [
    "# Advanced search with multiple filters\n",
    "models_filtered = scraper.search_models(\n",
    "    query=\"medieval architecture\",\n",
    "    categories='cultural-heritage-history',\n",
    "    downloadable=True,  # Only downloadable models\n",
    "    sort_by='-likeCount',  # Sort by most liked\n",
    "    max_results=30\n",
    ")\n",
    "\n",
    "df_medieval = scraper.to_dataframe(models_filtered)\n",
    "print(f\"Found {len(df_medieval)} downloadable medieval architecture models\")\n",
    "df_medieval[['name', 'likeCount', 'isDownloadable']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "comprehensive_search"
   },
   "source": [
    "## 4. Comprehensive Cultural Heritage Dataset\n",
    "\n",
    "Let's create a larger dataset for discourse analysis by searching multiple terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "large_dataset"
   },
   "outputs": [],
   "source": [
    "# Define search terms related to cultural heritage\n",
    "search_terms = [\n",
    "    \"archaeology\",\n",
    "    \"ancient\",\n",
    "    \"historical\",\n",
    "    \"monument\",\n",
    "    \"artifact\",\n",
    "    \"ruins\",\n",
    "    \"heritage\",\n",
    "    \"museum\"\n",
    "]\n",
    "\n",
    "all_models = []\n",
    "\n",
    "for term in search_terms:\n",
    "    print(f\"Searching for: {term}...\")\n",
    "    df_temp = scraper.search_cultural_heritage(\n",
    "        query=term,\n",
    "        max_results=100,\n",
    "        sort_by='-relevance'\n",
    "    )\n",
    "    all_models.append(df_temp)\n",
    "    print(f\"  Found {len(df_temp)} models\")\n",
    "\n",
    "# Combine all results\n",
    "df_combined = pd.concat(all_models, ignore_index=True)\n",
    "\n",
    "# Remove duplicates based on uid\n",
    "df_combined = df_combined.drop_duplicates(subset=['uid'], keep='first')\n",
    "\n",
    "print(f\"\\n‚úì Total unique models collected: {len(df_combined)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_exploration"
   },
   "source": [
    "## 5. Data Exploration and Analysis\n",
    "\n",
    "Now let's analyze the collected data to understand patterns in cultural heritage modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "basic_stats"
   },
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"Dataset Overview:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total models: {len(df_combined)}\")\n",
    "print(f\"Unique users: {df_combined['user_username'].nunique()}\")\n",
    "print(f\"Downloadable models: {df_combined['isDownloadable'].sum()}\")\n",
    "print(f\"\\nEngagement Statistics:\")\n",
    "print(f\"Total views: {df_combined['viewCount'].sum():,}\")\n",
    "print(f\"Total likes: {df_combined['likeCount'].sum():,}\")\n",
    "print(f\"Average views per model: {df_combined['viewCount'].mean():.1f}\")\n",
    "print(f\"Average likes per model: {df_combined['likeCount'].mean():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "top_models"
   },
   "outputs": [],
   "source": [
    "# Most popular models\n",
    "print(\"Top 10 Most Viewed Models:\")\n",
    "top_viewed = df_combined.nlargest(10, 'viewCount')[['name', 'user_displayName', 'viewCount', 'likeCount']]\n",
    "display(top_viewed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "top_creators"
   },
   "outputs": [],
   "source": [
    "# Most prolific creators\n",
    "creator_counts = df_combined['user_username'].value_counts().head(10)\n",
    "print(\"Top 10 Most Prolific Creators:\")\n",
    "display(creator_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualizations"
   },
   "source": [
    "## 6. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plot_engagement"
   },
   "outputs": [],
   "source": [
    "# Distribution of views and likes\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Views distribution (log scale)\n",
    "df_combined[df_combined['viewCount'] > 0]['viewCount'].apply(lambda x: np.log10(x+1)).hist(bins=50, ax=axes[0])\n",
    "axes[0].set_title('Distribution of Views (log scale)')\n",
    "axes[0].set_xlabel('log10(View Count)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "\n",
    "# Likes distribution (log scale)\n",
    "df_combined[df_combined['likeCount'] > 0]['likeCount'].apply(lambda x: np.log10(x+1)).hist(bins=50, ax=axes[1])\n",
    "axes[1].set_title('Distribution of Likes (log scale)')\n",
    "axes[1].set_xlabel('log10(Like Count)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plot_categories"
   },
   "outputs": [],
   "source": [
    "# Most common categories (if models have multiple categories)\n",
    "# Split and count all categories\n",
    "all_categories = df_combined['categories'].str.split(', ').explode()\n",
    "category_counts = all_categories.value_counts().head(15)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "category_counts.plot(kind='barh')\n",
    "plt.title('Top 15 Categories in Cultural Heritage Models')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Category')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plot_timeline"
   },
   "outputs": [],
   "source": [
    "# Publication timeline\n",
    "# Convert publishedAt to datetime\n",
    "df_combined['publishedAt'] = pd.to_datetime(df_combined['publishedAt'])\n",
    "df_combined['publishedYear'] = df_combined['publishedAt'].dt.year\n",
    "df_combined['publishedMonth'] = df_combined['publishedAt'].dt.to_period('M')\n",
    "\n",
    "# Plot by year\n",
    "yearly_counts = df_combined['publishedYear'].value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "yearly_counts.plot(kind='bar')\n",
    "plt.title('Cultural Heritage Models Published by Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Models')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "text_analysis"
   },
   "source": [
    "## 7. Discourse Analysis: Tags and Descriptions\n",
    "\n",
    "Analyze the language used by modelers to describe their cultural heritage models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "analyze_tags"
   },
   "outputs": [],
   "source": [
    "# Most common tags\n",
    "all_tags = df_combined['tags'].str.split(', ').explode()\n",
    "tag_counts = all_tags.value_counts().head(30)\n",
    "\n",
    "print(\"Top 30 Most Common Tags:\")\n",
    "display(tag_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tag_wordcloud"
   },
   "outputs": [],
   "source": [
    "# Word cloud of tags\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Combine all tags into a single string\n",
    "tags_text = ' '.join(all_tags.dropna().astype(str))\n",
    "\n",
    "# Create word cloud\n",
    "wordcloud = WordCloud(width=1200, height=600, background_color='white', \n",
    "                     colormap='viridis', max_words=100).generate(tags_text)\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud of Tags in Cultural Heritage Models', fontsize=16, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "analyze_descriptions"
   },
   "outputs": [],
   "source": [
    "# Analyze descriptions for common terms\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Combine all descriptions\n",
    "all_descriptions = ' '.join(df_combined['description'].fillna('').astype(str))\n",
    "\n",
    "# Extract words (simple tokenization)\n",
    "words = re.findall(r'\\b[a-z]{4,}\\b', all_descriptions.lower())\n",
    "\n",
    "# Common stopwords to exclude\n",
    "stopwords = {'this', 'that', 'with', 'from', 'have', 'been', 'were', 'their', \n",
    "             'there', 'what', 'when', 'where', 'which', 'who', 'will', 'would',\n",
    "             'could', 'should', 'about', 'these', 'those', 'more', 'than', 'into',\n",
    "             'such', 'some', 'other', 'them', 'then', 'also', 'only', 'very',\n",
    "             'much', 'many', 'most', 'made', 'make'}\n",
    "\n",
    "# Filter stopwords\n",
    "filtered_words = [w for w in words if w not in stopwords]\n",
    "\n",
    "# Count most common\n",
    "word_counts = Counter(filtered_words).most_common(30)\n",
    "\n",
    "print(\"Top 30 Words in Model Descriptions:\")\n",
    "for word, count in word_counts:\n",
    "    print(f\"{word:20s}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "keyword_analysis"
   },
   "outputs": [],
   "source": [
    "# Analyze specific discourse-related keywords\n",
    "discourse_keywords = {\n",
    "    'preservation': ['preserv', 'conserv', 'restor', 'protect'],\n",
    "    'authenticity': ['authentic', 'original', 'genuine', 'real', 'actual'],\n",
    "    'reconstruction': ['reconstruct', 'recreat', 'rebuild', 'remodel'],\n",
    "    'education': ['educat', 'learn', 'teach', 'study', 'research'],\n",
    "    'technology': ['scan', 'photogrammetry', 'laser', 'digital', '3d'],\n",
    "    'heritage': ['heritage', 'cultural', 'historic', 'legacy', 'tradition']\n",
    "}\n",
    "\n",
    "# Count occurrences\n",
    "discourse_counts = {}\n",
    "descriptions_lower = df_combined['description'].fillna('').str.lower()\n",
    "\n",
    "for category, keywords in discourse_keywords.items():\n",
    "    count = sum(descriptions_lower.str.contains('|'.join(keywords), regex=True))\n",
    "    discourse_counts[category] = count\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(discourse_counts.keys(), discourse_counts.values())\n",
    "plt.title('Discourse Themes in Model Descriptions')\n",
    "plt.xlabel('Theme')\n",
    "plt.ylabel('Number of Models Mentioning Theme')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nDiscourse Theme Frequency:\")\n",
    "for theme, count in discourse_counts.items():\n",
    "    percentage = (count / len(df_combined)) * 100\n",
    "    print(f\"{theme:20s}: {count:4d} models ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "license_analysis"
   },
   "source": [
    "## 8. License Analysis\n",
    "\n",
    "Examine licensing practices in cultural heritage models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "license_stats"
   },
   "outputs": [],
   "source": [
    "# License distribution\n",
    "license_counts = df_combined['license_label'].value_counts()\n",
    "\n",
    "print(\"License Distribution:\")\n",
    "display(license_counts)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "license_counts.plot(kind='bar')\n",
    "plt.title('Distribution of Licenses in Cultural Heritage Models')\n",
    "plt.xlabel('License Type')\n",
    "plt.ylabel('Number of Models')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "export"
   },
   "source": [
    "## 9. Export Data\n",
    "\n",
    "Save the collected data for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "export_csv"
   },
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "output_filename = f'cultural_heritage_models_{datetime.now().strftime(\"%Y%m%d\")}.csv'\n",
    "scraper.export_to_csv(df_combined, output_filename)\n",
    "\n",
    "print(f\"‚úì Data exported to {output_filename}\")\n",
    "print(f\"  Total records: {len(df_combined)}\")\n",
    "print(f\"  Columns: {', '.join(df_combined.columns.tolist())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "export_subset"
   },
   "outputs": [],
   "source": [
    "# Export a subset with key columns for qualitative analysis\n",
    "analysis_columns = [\n",
    "    'uid', 'name', 'description', 'tags', 'categories',\n",
    "    'user_username', 'user_displayName', \n",
    "    'license_label', 'publishedAt',\n",
    "    'viewCount', 'likeCount', 'commentCount',\n",
    "    'isDownloadable', 'viewerUrl'\n",
    "]\n",
    "\n",
    "df_analysis = df_combined[analysis_columns]\n",
    "analysis_filename = f'cultural_heritage_analysis_{datetime.now().strftime(\"%Y%m%d\")}.csv'\n",
    "scraper.export_to_csv(df_analysis, analysis_filename)\n",
    "\n",
    "print(f\"‚úì Analysis subset exported to {analysis_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "advanced_examples"
   },
   "source": [
    "## 10. Advanced Search Examples\n",
    "\n",
    "More sophisticated searches for specific research questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "search_by_user"
   },
   "outputs": [],
   "source": [
    "# Get all models from a specific user\n",
    "username = \"example_user\"  # Replace with actual username\n",
    "\n",
    "# Uncomment to run:\n",
    "# user_models = scraper.get_user_models(username, max_results=100)\n",
    "# df_user = scraper.to_dataframe(user_models)\n",
    "# print(f\"User {username} has {len(df_user)} models\")\n",
    "# display(df_user[['name', 'viewCount', 'likeCount']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "search_specific_license"
   },
   "outputs": [],
   "source": [
    "# Search for models with specific Creative Commons licenses\n",
    "cc_models = scraper.search_models(\n",
    "    query=\"archaeology\",\n",
    "    categories='cultural-heritage-history',\n",
    "    licenses=['cc0', 'by', 'by-sa'],  # CC0 and Attribution licenses\n",
    "    downloadable=True,\n",
    "    max_results=50\n",
    ")\n",
    "\n",
    "df_cc = scraper.to_dataframe(cc_models)\n",
    "print(f\"Found {len(df_cc)} openly licensed archaeology models\")\n",
    "print(\"\\nLicense breakdown:\")\n",
    "display(df_cc['license_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "search_by_complexity"
   },
   "outputs": [],
   "source": [
    "# Search for models by polygon count (complexity)\n",
    "# Useful for understanding modeling approaches\n",
    "\n",
    "low_poly_models = scraper.search_models(\n",
    "    query=\"ancient\",\n",
    "    categories='cultural-heritage-history',\n",
    "    max_face_count=50000,  # Low-poly models\n",
    "    max_results=30\n",
    ")\n",
    "\n",
    "high_poly_models = scraper.search_models(\n",
    "    query=\"ancient\",\n",
    "    categories='cultural-heritage-history',\n",
    "    min_face_count=500000,  # High-poly models\n",
    "    max_results=30\n",
    ")\n",
    "\n",
    "df_low_poly = scraper.to_dataframe(low_poly_models)\n",
    "df_high_poly = scraper.to_dataframe(high_poly_models)\n",
    "\n",
    "print(f\"Low-poly models (< 50k faces): {len(df_low_poly)}\")\n",
    "print(f\"High-poly models (> 500k faces): {len(df_high_poly)}\")\n",
    "print(f\"\\nAverage engagement comparison:\")\n",
    "print(f\"  Low-poly views:  {df_low_poly['viewCount'].mean():.0f}\")\n",
    "print(f\"  High-poly views: {df_high_poly['viewCount'].mean():.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "notes"
   },
   "source": [
    "## Notes and Best Practices\n",
    "\n",
    "### Rate Limiting\n",
    "- The scraper includes built-in rate limiting (default: 1.5 seconds between requests)\n",
    "- If you encounter 429 errors, increase the `rate_limit_delay` parameter\n",
    "- The scraper will automatically retry once after a 60-second wait\n",
    "\n",
    "### Data Ethics\n",
    "- Respect Sketchfab's Terms of Service\n",
    "- Use data responsibly for research purposes\n",
    "- Cite creators when using models or data in publications\n",
    "- Consider privacy implications when analyzing user data\n",
    "\n",
    "### Further Analysis\n",
    "- Use the exported CSV files for qualitative analysis\n",
    "- Consider sentiment analysis on descriptions\n",
    "- Network analysis of creator communities\n",
    "- Temporal analysis of modeling trends\n",
    "- Comparison across different cultural heritage categories\n",
    "\n",
    "### API Limitations\n",
    "- Public searches may have different limits than authenticated searches\n",
    "- Some model data may require authentication\n",
    "- Consider caching results to avoid redundant API calls\n",
    "\n",
    "### Citations\n",
    "When publishing research using this data, please cite:\n",
    "- Sketchfab as the data source\n",
    "- Individual creators where appropriate\n",
    "- The Sketchfab Data API: https://docs.sketchfab.com/data-api/v3/\n",
    "\n",
    "---\n",
    "\n",
    "**Happy researching!** üèõÔ∏èüìä"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Sketchfab Cultural Heritage Analysis",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
